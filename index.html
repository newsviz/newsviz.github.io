<html>
<head>
    <link rel="shortcut icon"
    href="./favicon.ico">

<link href="https://fonts.googleapis.com/css?family=Roboto+Mono&display=swap" rel="stylesheet">
<style>
        body {
            font-family: 'Roboto Mono', monospace;
        }
      </style>
  </head>
<body>

  <div align="center">
      <div align="left" style="width: 60%;">


<h1>NewsViz Project</h1>
<ul>
<li><a href="https://github.com/newsviz/newsviz">Исходный код проекта</a></li>
<li><a href="https://ods.ai/projects/news-viz">Страница проекта на ods.ai</a></li>
<li><a href="http://151.115.54.189:8080/">Демо-страница проекта</a></li>
</ul>
<h2>Что за проект то</h2>
<p>Мы делаем инструмент для визуализации развития
     <a href="www.machinelearning.ru/wiki/index.php?title=Тематическое_моделирование">тем в текстах</a> 
     по времени. Изначальной целью была визуализация русскоязычных новостей.
      Сейчас это инструмент общего назначения, но для демонстрации мы всё равно используем новости.    
</p>
<h2>Дисклеймер</h2>
<p>Проект в активной разработке. Впереди ещё очень много работы. 
    Сейчас есть только минимальный функционал пригодный для демонстрации.
     Это опенсорс, так что вы можете помочь проекту сообщая об ошибках и дополняя исходный код.</p>
<h2>Как это работает</h2>
<p>Мы используем машинное обучение. Основная фишка - это тематическое моделирование.
    В двух словах - это когда мы скармливаем алгоритму много текстов, а он 
    определяет какие темы из них можно выделить и какие документы к этим темам 
    принадлежат. Более подробное описание с техническими подробностями будет ниже.</p>
    <p>Мы берём данные, очищаем их, разбиваем на рубрики, и рубрики уже тематизируем.
         На графиках рисуем суммарную принадлежность документов к каждой теме в данный момент времени.</p>
<h2>Как читать графики</h2>
<p>Считайте, что это насколько какие-то темы проявлены в текстах в каждый отдельный промежуток времени. 
    После тематизации мы получаем для каждого документа (новости) насколько она
     принадлежит какой-то теме. То есть, документ может быть на 10% одной темы,
      на 90% другой, или иметь любое другое соотношение тем. Для графиков мы суммируем 
    такие доли по всем документам для каждого временного отрезка. 
    Смысл имеют только относительные масштабы, то есть, что в январе
     тема 1 в 10 раз интенсивнее, чем тема 2, или что она стала более явной в феврале.</p>
<h2>Чуть больше технических деталей</h2>
<p>
    <ul>
    <li>Лучше заглянуть к нам в репозиторий, но коротко перескажем здесь: 
    Сначала качаем данные</li>

    <li>Потом делаем препроцессинг: очистку, токенизацию и лемматизацию. 
    Текущая версия заточена под русский язык, и требует доработки 
    (немного мусорных символов и стоп-слов мы пропустили), но архитектура 
    позволяет заменить препроцессинг на другой.</li>

    <li>Следом делаем классификацию. У нас есть рубрики, которые соответствуют 
    разделам новостных сайтов и они используются для того, чтобы обучить классификатор 
    приводить все тексты к одинаковой разметке. Это делается для того, 
    чтобы улучшить качество следующего этапа.</li>

    <li>Затем тематическое моделирование. Мы используем bigARTM, потому что он оказался 
    достаточно быстрым и качественным. До этого пробовали много всего.</li>
</ul>
</p>
<h2></h2>
<p></p>
<h2></h2>
<p></p>


</div>
</div>
</body>

</html>